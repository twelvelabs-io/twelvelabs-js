/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as TwelvelabsApi from "../../../../../../../../index";

/**
 * @example
 *     {
 *         inputType: "audio",
 *         modelName: "marengo3.0",
 *         audio: {
 *             mediaSource: {
 *                 url: "https://user-bucket.com/audio/long-audio.wav"
 *             },
 *             startSec: 0,
 *             endSec: 3600,
 *             segmentation: {
 *                 strategy: "fixed",
 *                 fixed: {
 *                     durationSec: 6
 *                 }
 *             },
 *             embeddingOption: ["audio", "transcription"],
 *             embeddingScope: ["clip", "asset"]
 *         }
 *     }
 *
 * @example
 *     {
 *         inputType: "video",
 *         modelName: "marengo3.0",
 *         video: {
 *             mediaSource: {
 *                 url: "https://user-bucket.com/video/long-video.mp4"
 *             },
 *             startSec: 0,
 *             endSec: 7200,
 *             segmentation: {
 *                 strategy: "dynamic",
 *                 dynamic: {
 *                     minDurationSec: 4
 *                 }
 *             },
 *             embeddingOption: ["visual", "audio", "transcription"],
 *             embeddingScope: ["clip", "asset"]
 *         }
 *     }
 */
export interface CreateAsyncEmbeddingRequest {
    /**
     * The type of content for the embeddings.
     *
     * **Values**:
     * - `audio`: Audio files
     * - `video`: Video content
     */
    inputType: TwelvelabsApi.embed.v2.CreateAsyncEmbeddingRequestInputType;
    /** The model you wish to use. Only `"marengo3.0"` is supported. */
    modelName: TwelvelabsApi.embed.v2.CreateAsyncEmbeddingRequestModelName;
    audio?: TwelvelabsApi.AudioInputRequest;
    video?: TwelvelabsApi.VideoInputRequest;
}
