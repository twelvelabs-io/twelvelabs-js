/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as TwelvelabsApi from "../../../../../../index";

/**
 * @example
 *     {
 *         inputType: "text",
 *         modelName: "marengo3.0",
 *         text: {
 *             inputText: "man walking a dog"
 *         }
 *     }
 *
 * @example
 *     {
 *         inputType: "image",
 *         modelName: "marengo3.0",
 *         image: {
 *             mediaSource: {
 *                 url: "https://user-bucket.com/folder/dog.jpg"
 *             }
 *         }
 *     }
 *
 * @example
 *     {
 *         inputType: "text_image",
 *         modelName: "marengo3.0",
 *         textImage: {
 *             mediaSource: {
 *                 url: "https://user-bucket.com/folder/dog.jpg"
 *             },
 *             inputText: "man walking a dog"
 *         }
 *     }
 *
 * @example
 *     {
 *         inputType: "image",
 *         modelName: "marengo3.0",
 *         image: {
 *             mediaSource: {
 *                 assetId: "1234567890"
 *             }
 *         }
 *     }
 *
 * @example
 *     {
 *         inputType: "audio",
 *         modelName: "marengo3.0",
 *         audio: {
 *             mediaSource: {
 *                 url: "https://user-bucket.com/audio/a.wav"
 *             },
 *             startSec: 0,
 *             endSec: 6,
 *             segmentation: {
 *                 strategy: "fixed",
 *                 fixed: {
 *                     durationSec: 6
 *                 }
 *             },
 *             embeddingOption: ["audio", "transcription"],
 *             embeddingScope: ["clip", "asset"]
 *         }
 *     }
 *
 * @example
 *     {
 *         inputType: "video",
 *         modelName: "marengo3.0",
 *         video: {
 *             mediaSource: {
 *                 url: "https://user-bucket.com/video/clip.mp4"
 *             },
 *             startSec: 0,
 *             endSec: 12,
 *             segmentation: {
 *                 strategy: "dynamic",
 *                 dynamic: {
 *                     minDurationSec: 4
 *                 }
 *             },
 *             embeddingOption: ["visual", "audio", "transcription"],
 *             embeddingScope: ["clip", "asset"]
 *         }
 *     }
 *
 * @example
 *     {
 *         inputType: "video",
 *         modelName: "marengo3.0",
 *         video: {
 *             mediaSource: {
 *                 url: "https://user-bucket.com/video/simple.mp4"
 *             }
 *         }
 *     }
 *
 * @example
 *     {
 *         inputType: "audio",
 *         modelName: "marengo3.0",
 *         audio: {
 *             mediaSource: {
 *                 url: "https://user-bucket.com/audio/speech.wav"
 *             },
 *             embeddingOption: ["transcription"],
 *             embeddingScope: ["asset"]
 *         }
 *     }
 *
 * @example
 *     {
 *         inputType: "text",
 *         modelName: "marengo3.0",
 *         text: {
 *             inputText: "man walking a dog"
 *         }
 *     }
 *
 * @example
 *     {
 *         inputType: "text",
 *         modelName: "marengo3.0",
 *         text: {
 *             inputText: "man walking a dog"
 *         }
 *     }
 *
 * @example
 *     {
 *         inputType: "text",
 *         modelName: "marengo3.0",
 *         text: {
 *             inputText: "man walking a dog"
 *         }
 *     }
 */
export interface CreateEmbeddingsRequest {
    /** The type of content for which you wish to create embeddings. */
    inputType: TwelvelabsApi.embed.CreateEmbeddingsRequestInputType;
    /** The video understanding model you wish to use. */
    modelName: string;
    text?: TwelvelabsApi.TextInputRequest;
    image?: TwelvelabsApi.ImageInputRequest;
    textImage?: TwelvelabsApi.TextImageInputRequest;
    audio?: TwelvelabsApi.AudioInputRequest;
    video?: TwelvelabsApi.VideoInputRequest;
}
