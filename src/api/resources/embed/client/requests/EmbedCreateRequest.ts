/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as fs from "fs";

/**
 * @example
 *     {
 *         modelName: "model_name"
 *     }
 */
export interface EmbedCreateRequest {
    /**
     * The name of the model you want to use. The following models are available:
     *   - `Marengo-retrieval-2.7`
     */
    modelName: string;
    /**
     * The text for which you wish to create an embedding.
     *
     * <Note title="Note">
     * Text embeddings are limited to 77 tokens. If the text exceeds this limit, the platform truncates it according to the value of the `text_truncate` parameter described below.
     * </Note>
     *
     * **Example**: "Man with a dog crossing the street"
     */
    text?: string;
    /**
     * Specifies how the platform truncates text that exceeds 77 tokens to fit the maximum length allowed for an embedding.
     * This parameter can take one of the following values:
     * - `start`: The platform will truncate the start of the provided text.
     * - `end`: The platform will truncate the end of the provided text.
     * - `none`: The platform will return an error if the text is longer than the maximum token limit.
     *
     * **Default**: `end`
     */
    textTruncate?: string;
    /** The publicly accessible URL of the image for which you wish to create an embedding. This parameter is required for image embeddings if `image_file` is not provided. */
    imageUrl?: string;
    imageFile?: File | fs.ReadStream | Blob | undefined;
    /** The publicly accessible URL of the audio file for which you wish to creae an emebdding. This parameter is required for audio embeddings if `audio_file` is not provided. */
    audioUrl?: string;
    audioFile?: File | fs.ReadStream | Blob | undefined;
    /**
     * Specifies the start time, in seconds, from which the platform generates the audio embeddings. This parameter allows you to skip the initial portion of the audio during processing.
     * **Default**: `0`.
     */
    audioStartOffsetSec?: number;
}
