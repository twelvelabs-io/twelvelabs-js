/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as environments from "../../../../environments";
import * as core from "../../../../core";
import * as TwelvelabsApi from "../../../index";
import urlJoin from "url-join";
import * as serializers from "../../../../serialization/index";
import * as errors from "../../../../errors/index";
import { Tasks } from "../resources/tasks/client/Client";

export declare namespace Embed {
    export interface Options {
        environment?: core.Supplier<environments.TwelvelabsApiEnvironment | string>;
        /** Specify a custom URL to connect the client to. */
        baseUrl?: core.Supplier<string>;
        apiKey?: core.Supplier<string>;
    }

    export interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
        /** Additional headers to include in the request. */
        headers?: Record<string, string>;
    }
}

export class Embed {
    protected _tasks: Tasks | undefined;

    constructor(protected readonly _options: Embed.Options = {}) {}

    public get tasks(): Tasks {
        return (this._tasks ??= new Tasks(this._options));
    }

    /**
     * This method creates embeddings for text, image, and audio content.
     *
     * Before you create an embedding, ensure that your image or audio files meet the following prerequisites:
     * - [Image embeddings](/v1.3/docs/guides/create-embeddings/image#prerequisites)
     * - [Audio embeddings](/v1.3/docs/guides/create-embeddings/audio#prerequisites)
     *
     * Parameters for embeddings:
     * - **Common parameters**:
     *   - `model_name`: The video understanding model you want to use. Example: "Marengo-retrieval-2.7".
     * - **Text embeddings**:
     *   - `text`: Text for which to create an embedding.
     * - **Image embeddings**:
     *   Provide one of the following:
     *   - `image_url`: Publicly accessible URL of your image file.
     *   - `image_file`:  Local image file.
     * - **Audio embeddings**:
     *   Provide one of the following:
     *   - `audio_url`: Publicly accessible URL of your audio file.
     *   - `audio_file`: Local audio file.
     *
     * <Note title="Notes">
     * - The Marengo video understanding model generates embeddings for all modalities in the same latent space. This shared space enables any-to-any searches across different types of content.
     * - You can create multiple types of embeddings in a single API call.
     * - Audio embeddings combine generic sound and human speech in a single embedding. For videos with transcriptions, you can retrieve transcriptions and then [create text embeddings](/v1.3/api-reference/text-image-audio-embeddings/create-text-image-audio-embeddings) from these transcriptions.
     * </Note>
     *
     * @param {TwelvelabsApi.EmbedCreateRequest} request
     * @param {Embed.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link TwelvelabsApi.BadRequestError}
     *
     * @example
     *     await client.embed.create({
     *         modelName: "model_name"
     *     })
     */
    public create(
        request: TwelvelabsApi.EmbedCreateRequest,
        requestOptions?: Embed.RequestOptions,
    ): core.HttpResponsePromise<TwelvelabsApi.EmbeddingResponse> {
        return core.HttpResponsePromise.fromPromise(this.__create(request, requestOptions));
    }

    private async __create(
        request: TwelvelabsApi.EmbedCreateRequest,
        requestOptions?: Embed.RequestOptions,
    ): Promise<core.WithRawResponse<TwelvelabsApi.EmbeddingResponse>> {
        const _request = await core.newFormData();
        _request.append("model_name", request.modelName);
        if (request.text != null) {
            _request.append("text", request.text);
        }

        if (request.textTruncate != null) {
            _request.append("text_truncate", request.textTruncate);
        }

        if (request.imageUrl != null) {
            _request.append("image_url", request.imageUrl);
        }

        if (request.imageFile != null) {
            await _request.appendFile("image_file", request.imageFile);
        }

        if (request.audioUrl != null) {
            _request.append("audio_url", request.audioUrl);
        }

        if (request.audioFile != null) {
            await _request.appendFile("audio_file", request.audioFile);
        }

        if (request.audioStartOffsetSec != null) {
            _request.append("audio_start_offset_sec", request.audioStartOffsetSec.toString());
        }

        const _maybeEncodedRequest = await _request.getRequest();
        const _response = await core.fetcher({
            url: urlJoin(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.TwelvelabsApiEnvironment.Default,
                "embed",
            ),
            method: "POST",
            headers: {
                "X-Fern-Language": "JavaScript",
                "X-Fern-SDK-Name": "twelvelabs-js",
                "X-Fern-SDK-Version": "1.0.2",
                "User-Agent": "twelvelabs-js/1.0.2",
                "X-Fern-Runtime": core.RUNTIME.type,
                "X-Fern-Runtime-Version": core.RUNTIME.version,
                ...(await this._getCustomAuthorizationHeaders()),
                ..._maybeEncodedRequest.headers,
                ...requestOptions?.headers,
            },
            requestType: "file",
            duplex: _maybeEncodedRequest.duplex,
            body: _maybeEncodedRequest.body,
            timeoutMs: requestOptions?.timeoutInSeconds != null ? requestOptions.timeoutInSeconds * 1000 : 60000,
            maxRetries: requestOptions?.maxRetries,
            abortSignal: requestOptions?.abortSignal,
        });
        if (_response.ok) {
            return {
                data: serializers.EmbeddingResponse.parseOrThrow(_response.body, {
                    unrecognizedObjectKeys: "passthrough",
                    allowUnrecognizedUnionMembers: true,
                    allowUnrecognizedEnumValues: true,
                    breadcrumbsPrefix: ["response"],
                }),
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 400:
                    throw new TwelvelabsApi.BadRequestError(_response.error.body, _response.rawResponse);
                default:
                    throw new errors.TwelvelabsApiError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        switch (_response.error.reason) {
            case "non-json":
                throw new errors.TwelvelabsApiError({
                    statusCode: _response.error.statusCode,
                    body: _response.error.rawBody,
                    rawResponse: _response.rawResponse,
                });
            case "timeout":
                throw new errors.TwelvelabsApiTimeoutError("Timeout exceeded when calling POST /embed.");
            case "unknown":
                throw new errors.TwelvelabsApiError({
                    message: _response.error.errorMessage,
                    rawResponse: _response.rawResponse,
                });
        }
    }

    protected async _getCustomAuthorizationHeaders() {
        const apiKeyValue = (await core.Supplier.get(this._options.apiKey)) ?? process?.env["TWELVE_LABS_API_KEY"];
        return { "x-api-key": apiKeyValue };
    }
}
