/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as TwelvelabsApi from "../../../../index";
import * as fs from "fs";

/**
 * @example
 *     {
 *         indexId: "index_id",
 *         searchOptions: ["visual"]
 *     }
 */
export interface SearchCreateRequest {
    /** The type of media you wish to use. This parameter is required for media queries. For example, to perform an image-based search, set this parameter to `image`. Use `query_text` together with this parameter when you want to perform a composed image+text search. */
    queryMediaType?: TwelvelabsApi.SearchCreateRequestQueryMediaType;
    /** The publicly accessible URL of the media file you wish to use. This parameter is required for media queries if `query_media_file` is not provided. */
    queryMediaUrl?: string;
    queryMediaFile?: File | fs.ReadStream | Blob | undefined;
    /**
     * The text query to search for. This parameter is required for text queries. Note that the platform supports full natural language-based search. You can use this parameter together with `query_media_type` and `query_media_url` or `query_media_file` to perform a composed image+text search.
     *
     * If you're using the Entity Search feature to search for specific persons in your video content, you must enclose the unique identifier of your entity between the `<@` and `>` markers. For example, to search for an entity with the ID `entity123`, use `<@entity123> is walking` as your query.
     *
     *
     * The maximum query length varies by model. Marengo 3.0 supports up to 500 tokens per query, while Marengo 2.7 supports up to 77 tokens per query.
     */
    queryText?: string;
    /** The unique identifier of the index to search. */
    indexId: string;
    /**
     * Specifies the modalities the video understanding model uses to find relevant information.
     *
     * Available options:
     * - `visual`: Searches visual content.
     * - `audio`: Searches non-speech audio (Marengo 3.0) or all audio (Marengo 2.7).
     * - `transcription`: Spoken words (Marengo 3.0 only)
     *
     * <Note title="Note">
     * - You can specify multiple search options in conjunction with the [`operator`](/v1.3/api-reference/any-to-video-search/make-search-request#request.body.operator.operator) parameter described below to broaden or narrow your search. For example, to search using both visual and non-speech audio content, include this parameter two times in the request as shown below:
     *   ```JSON
     *   --form search_options=visual \
     *   --form search_options=audio \
     *   --form search_options=transcription \
     *   ```
     * </Note>
     *
     * For detailed guidance and version-specific behavior, see the [Search options](/v1.3/docs/concepts/modalities#search-options) section.
     */
    searchOptions: TwelvelabsApi.SearchCreateRequestSearchOptionsItem[];
    /**
     * Specifies how the platform matches your text query with the words spoken in the video. This parameter applies only when using Marengo 3.0 with the `search_options` parameter containing the `transcription` value.
     *
     * Available options:
     * - `lexical`: Exact word matching
     * - `semantic`: Meaning-based matching
     *
     * For details on when to use each option, see the [Transcription options](/v1.3/docs/concepts/modalities#transcription-options) section.
     *
     * **Default**: `["lexical", "semantic"]`.
     */
    transcriptionOptions?: TwelvelabsApi.SearchCreateRequestTranscriptionOptionsItem[];
    /**
     * <Info>
     *   This parameter is deprecated in Marengo 3.0 and newer versions. Use the [`rank`](/v1.3/api-reference/any-to-video-search/make-search-request#response.body.data.rank) field in the response instead, which indicates the relevance ranking assigned by the model.
     * </Info>
     * This parameter specifies the strictness of the thresholds for assigning the high, medium, or low confidence levels to search results. If you use a lower value, the thresholds become more relaxed, and more search results will be classified as having high, medium, or low confidence levels. You can use this parameter to include a broader range of potentially relevant video clips, even if some results might be less precise.
     *
     * **Min**: 0
     * **Max**: 1
     * **Default:** 0.5
     */
    adjustConfidenceLevel?: number;
    /**
     * Use this parameter to group or ungroup items in a response. It can take one of the following values:
     * - `video`:  The platform will group the matching video clips in the response by video.
     * - `clip`: The matching video clips in the response will not be grouped.
     *
     * **Default:** `clip`
     */
    groupBy?: TwelvelabsApi.SearchCreateRequestGroupBy;
    threshold?: TwelvelabsApi.ThresholdSearch;
    /**
     * <Info>
     *   This parameter is deprecated in Marengo 3.0 and newer versions. Use the [`rank`](/v1.3/api-reference/any-to-video-search/make-search-request#response.body.data.rank) field in the response instead, which indicates the relevance ranking assigned by the model.
     * </Info>
     *
     * Use this parameter to specify the sort order for the response.
     *
     * When performing a search, the platform assigns a relevance ranking to each video clip that matches your search terms. By default, the search results are sorted by relevance ranking in ascending order, with 1 being the most relevant result.
     *
     * If you set this parameter to `score` and `group_by` is set to `video`, the platform will determine the highest relevance ranking (lowest number) for each video and sort the videos in the response by this ranking. For each video, the matching video clips will be sorted by relevance ranking in ascending order.
     *
     * If you set this parameter to `clip_count` and `group_by` is set to `video`, the platform will sort the videos in the response by the number of clips. For each video, the matching video clips will be sorted by relevance ranking in ascending order. You can use `clip_count` only when the matching video clips are grouped by video.
     *
     *
     * **Default:** `score`
     */
    sortOption?: TwelvelabsApi.SearchCreateRequestSortOption;
    /**
     * Combines multiple search options using `or` or `and`. Use `and` to find segments matching all search options. Use `or` to find segments matching any search option. For detailed guidance on using this parameter, see the [Combine multiple modalities](/v1.3/docs/concepts/modalities#combine-multiple-modalities) section.
     *
     * **Default**: `or`.
     */
    operator?: TwelvelabsApi.SearchCreateRequestOperator;
    /**
     * The number of items to return on each page. When grouping by video, this parameter represents the number of videos per page. Otherwise, it represents the maximum number of video clips per page.
     *
     * **Max**: `50`.
     */
    pageLimit?: number;
    /**
     * Specifies a stringified JSON object to filter your search results. Supports both system-generated metadata (example: video ID, duration) and user-defined metadata.
     *
     * **Syntax for filtering**
     *
     * The following table describes the supported data types, operators, and filter syntax:
     *
     * | Data type | Operator | Description | Syntax |
     * |:----------|:---------|:------------|:-------|
     * | String | `=` | Matches results equal to the specified value. | `{"field": "value"}`
     * | Array of strings | `=` | Matches results with any value in the specified array. Supported only for `id`. | `{"id": ["value1", "value2"]}` |
     * | Numeric (integer, float) | `=`, `lte`, `gte` | Matches results equal to or within a range of the specified value. | `{"field": number}` or `{"field": { "gte": number, "lte": number }}` |
     * | Boolean | `=` | Matches results equal to the specified boolean value. | `{"field": true}` or `{"field": false}`. |
     *
     * <br/>
     * **System-generated metadata**
     *
     * The table below describes the system-generated metadata available for filtering your  search results:
     *
     * | Field name | Description | Type | Example |
     * |:-----------|:------------|:-----|:--------|
     * | `id` | Filters by specific video IDs. | Array of strings | `{"id": ["67cec9caf45d9b64a58340fc", "67cec9baf45d9b64a58340fa"]}`. |
     * | `duration` | Filters based on the duration of the video containing the segment that matches your query. | Number or object with `gte` and `lte` | `{"duration": 600}` or `{"duration": { "gte": 600, "lte": 800 }}` |
     * | `width` | Filters by video width (in pixels). | Number or object with `gte` and `lte` | `{"width": 1920}` or `{"width": { "gte": 1280, "lte": 1920}}` |
     * | `height` | Filters by video height (in pixels). | Number or object with `gte` and `lte`. | `{"height": 1080}` or `{"height": { "gte": 720, "lte": 1080 }}`. |
     * | `size` | Filters by video size (in bytes) | Number or object with `gte` and `lte`. | `{"size": 1048576}` or `{"size": { "gte": 1048576, "lte": 5242880}}` |
     * | `filename` | Filters by the exact file name. | String | `{"filename": "Animal Encounters part 1"}` |
     *
     * <br/>
     * **User-defined metadata**
     *
     * To filter by user-defined metadata:
     * 1. Add metadata to your video by calling the [`PUT`](/v1.3/api-reference/videos/update) method of the `/indexes/:index-id/videos/:video-id` endpoint
     * 2. Reference the custom field in your filter object. For example, to filter videos where a custom field named `needsReview` of type boolean is `true`, use `{"needs_review": true}`.
     *
     * For more details and examples, see the [Filter search results](/v1.3/docs/guides/search/filtering) page.
     */
    filter?: string;
    /** Specifies whether to include user-defined metadata in the search results. */
    includeUserMetadata?: boolean;
}
