/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as TwelvelabsApi from "../index";

/**
 * This field is required if `input_type` is `audio`.
 */
export interface AudioInputRequest {
    mediaSource: TwelvelabsApi.MediaSource;
    /**
     * The start time in seconds for processing the audio file.
     *
     * Use this parameter to process a portion of the audio file starting from a specific time.
     *
     * **Default**: 0 (start from the beginning).
     */
    startSec?: number;
    /**
     * The end time in seconds for processing the audio file.
     *
     * Use this parameter to process a portion of the audio file ending at a specific time. The end time must be greater than the start time.
     *
     * **Default**: End of the audio file
     */
    endSec?: number;
    segmentation?: TwelvelabsApi.AudioSegmentation;
    /**
     * The types of embeddings you wish to generate.
     *
     * **Values**:
     * - `audio`: Generates embeddings based on audio content (sounds, music, effects)
     * - `transcription`: Generates embeddings based on transcribed speech
     *
     * You can specify multiple options to generate different types of embeddings for the same audio.
     */
    embeddingOption?: TwelvelabsApi.AudioInputRequestEmbeddingOptionItem[];
    /**
     * The scope for which you wish to generate embeddings.
     *
     * **Values**:
     * - `clip`: Generates one embedding for each segment
     * - `asset`: Generates one embedding for the entire audio file
     *
     * You can specify multiple scopes to generate embeddings at different levels.
     */
    embeddingScope?: TwelvelabsApi.AudioInputRequestEmbeddingScopeItem[];
}
