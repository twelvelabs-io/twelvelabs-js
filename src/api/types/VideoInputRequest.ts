/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as TwelvelabsApi from "../index";

/**
 * Required if the `input_type` parameter is `video`.
 */
export interface VideoInputRequest {
    mediaSource: TwelvelabsApi.MediaSource;
    /**
     * The start time in seconds for processing the video file.
     *
     * Use this parameter to process a portion of the video file starting from a specific time.
     *
     * **Default**: 0 (start from the beginning)
     */
    startSec?: number;
    /**
     * The end time in seconds for processing the video file.
     *
     * Use this parameter to process a portion of the video file ending at a specific time. The end time must be greater than the start time.
     * **Default**: End of the video file
     */
    endSec?: number;
    segmentation?: TwelvelabsApi.VideoSegmentation;
    /**
     * The types of embeddings to generate for the video.
     *
     * **Values:**
     * - `visual`: Generates embeddings based on visual content (scenes, objects, actions)
     * - `audio`: Generates embeddings based on audio content (sounds, music, effects)
     * - `transcription`: Generates embeddings based on transcribed speech
     *
     * You can specify multiple options to generate different types of embeddings for the same video.
     *
     * **Default**: `["visual", "audio", "transcription"]`
     */
    embeddingOption?: TwelvelabsApi.VideoInputRequestEmbeddingOptionItem[];
    /**
     * The scope for which you wish to generate embeddings.
     *
     * **Values**:
     * - `clip`: Generates one embedding for each segment
     * - `asset`: Generates one embedding for the entire video file. Use this scope for videos up to 10-30 seconds to maintain optimal performance.
     *
     * You can specify multiple scopes to generate embeddings at different levels.
     *
     * **Default**: `["clip", "asset"]`
     */
    embeddingScope?: TwelvelabsApi.VideoInputRequestEmbeddingScopeItem[];
}
